---
createdAt: 2024-07-28
updatedAt: 2025-04-25
isPublished: false
title: About the future of AI and search with Aravind Srinivas from Perplexity
---

Medium: podcast
Guests: [[Aravind Srinivas]]
Host: [[Lex Fridman]]
Topics: [[AI]], [[Semantic search]]
Readwise: [Readwise](https://readwise.io/bookreview/42619028)
Source: [Episode page](https://lexfridman.com/aravind-srinivas), [YouTube](https://www.youtube.com/watch?v=e-gwvmhyU7A), [Spotify](https://spoti.fi/2nEwCF8)

- ==_Answer engine_ instead of Search engine==
- Identifying your core metric that makes people stick around (e.g. Facebook had a number of your friends that are already on the platform when you sign up, Uber had a number of successful rides people complete)
- Write some strategic docs every now and then. Not to be shared around, but to clarify your own thinking. Do this even early on when action trumps processes and documenation.
- Building frontier open source models is a way to get more eyes on the system, more people to poke holes in it and ultimately a good and quick way to come up with guardrails
- LLMs have a huge memory, it’s like writing an open book test where you have access to all your notes and materials, but reasoning doesn’t imply you need to have a robust memory
- So it might be a stretch to say that the current generation of models has reasoning capabilities. Microsoft is working on a SLM (small language model) that is trained only on reasoning
- Programming is a solid proxy for reasoning capabilities, the better you are solving coding problems, the better are your reasoning abilities (this may explain why there is so much focus in this domain)
- We can probably create a model that can reason as well as Fayman, come up with innovative and intricate solutions to specific problems, but ==it’s not clear we can create that innate curiosity that is the driving force of humanity==
- [[Aravind Srinivas]] illustrates the reasoning capabilities on the cause and origins of COVID - we don’t have a mutually agreed on answer to this that would be verifiable, if an AI can come up with answers to such thorny issue than we can consider it truly intelligent
- It’s possible to build a system that can come up with novel ideas and truths. It’s more a question of when it will happen rather than if it’s possible.
- It’s likely that the most new value creation can be created in product development rather than foundational LLMs
- Aim for building a product that whenever AIs improve your product as a whole improves.
- Perplexity is model agnostic, they are looking to spark curiosity and give the best answers (not compete on the foundational models)
- Right now, more compute has an edge, but breakthroughs can lead to smaller models that can reason well by ==decoupling reasoning and facts==
